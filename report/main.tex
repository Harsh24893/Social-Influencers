\documentclass[conference]{IEEEtran}
\usepackage{blindtext, graphicx}
% correct bad hyphenation here
\usepackage[english]{babel} % English language/hyphenation
\usepackage{array}
\usepackage{multirow}
\usepackage{amsmath}
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}
\usepackage{caption}
\usepackage{listings}
\usepackage{color}
 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}
\begin{document}

%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{A Comparative study of different Machine Learning techniques on Kaggle Twitter Social Influencers Data Set}
\author{\IEEEauthorblockN{Arora, Pragya\IEEEauthorrefmark{1},
Ghai, Piyush\IEEEauthorrefmark{2}, Gupta, 


\IEEEauthorrefmark{3} and
Ramkrishnan, Navnith\IEEEauthorrefmark{4}}
\IEEEauthorblockA{Department of Computer Science \& Engineering,
The Ohio State University\\
Columbus, OH 43202\\
Email: \IEEEauthorrefmark{1}arora.170@osu.edu,
\IEEEauthorrefmark{2}ghai.8@osu.edu,
\IEEEauthorrefmark{3}gupta.749@osu.edu,
\IEEEauthorrefmark{4}ramkrishnan.1@osu.edu}}
\maketitle


\begin{abstract}
%\boldmath
Social media like twitter has given advent to growing importance to understand the behavior of these networks. More importantly these graph networks shows different patterns which are interesting to analyze. Some nodes becomes almost a sink where as some node acts like a source of outgoing links. Understanding these patterns will help in various applications and specially in experiments like Network A/B Testing where we need to introduce some new features to a treatment group restricting the control group. In out project we intended to experiment and analyze on one such pattern where we try to identify which node is more influential when compared to another node. To understand such a behavior we used a Twitter network data set which had 11 features for each node and we applied machine learning techniques to understanding the underlying features to classify the task at hand.
 
\end{abstract}
% IEEEtran.cls defaults to using nonbold math in the Abstract.
% This preserves the distinction between vectors and scalars. However,
% if the journal you are submitting to favors bold math in the abstract,
% then you can use LaTeX's standard command \boldmath at the very start
% of the abstract to achieve this. Many IEEE journals frown on math
% in the abstract anyway.

% Note that keywords are not normally used for peerreview papers.
\section{Introduction}
The growing importance of Social Networks has given an impetus to understand more about its implications because networks like these can influence millions of people. Contrary to paper or television media, social media is far more reaching to the audiences across the world and information exchange has never seen such a revolution. The need of the time is to have an The ability to understand the nuances of these networks because with more connectivity it becomes crucial to understand the behavior of different nodes in the network.

Some nodes/users are more important than others as there behavior affects a larger sets of nodes in the graph. When a user of such a graph is using the network she/he may find some activity shared by some of the other nodes more striking than others. A lot of psychological and cognitive science study shows that ones life is greatly impacted by her/his immediately surrounding and their influence. As social network has become a part of everyone's life, it has become important which are the nodes which has more impact on others i.e which are influential. One application of such a study is to predict what is the general mood of the crowd during election by analyzing the social network handle of all the candidates who stood for it. 

In this project, we address a targeted challenge of this problem presented in a Kaggle\cite{kaggle} competition from 2013 , in which influencers on Twitter is predicted from a set of features derived from user activity on the network, such as follower count, retweets received, etc. Rather than identifying influencers in the larger network, we are asked to simply identify which of a pair of users, A and B, is more influential, based on information about their respective activity in the network. This is a binary-classification problem. To find an optimal prediction method, we applied pre-processing methods including feature transformations. We used four different machine learning algorithms : Logistic Regression, Support Vector Machines (SVM), Neural Network, and Gradient Boosting, to model the data. We also tried varying some of the decision boundary options for the SVM by using different kernels and neural network classifiers by varying the activation functions on the hidden layer. Our approach includes a few methods that we did not see in other attempts at this problem, specifically a logarithmic feature transformation, the application of feature selection and gradient boosting. Outside of gradient boosting, the model configurations which produced the best results used linear-like decision boundaries (Logistic Regression).
 
\section{DATASET}\label{sec:page-layout}

This section expands on the data set which we used to try the different models on. 

\subsection{Original Dataset}\label{sec:formatting}
The data set which we used came from a Kaggle contest. The data set had the following files : 
\begin{itemize}
  \item train.csv
  \item test.csv
  \item sample\_predicitions.csv
\end{itemize}

The train.csv file contains data points where each data point is a pair wise features for two users along with a binary value which reflects which user is more influential. If the value is 0 the first user is more influential and vice-verse. Each user has 11 unique features which are extracted from their twitter profile and recorded in numeric form. The 11 features extracted includes:

\begin{itemize}
  \item Followers
  \item Following
  \item Listed
  \item Mentions received
  \item Re-tweets received
  \item Mentions sent
  \item Re-tweets sent
  \item Posts
  \item Network Feature 1
  \item Network Feature 2
  \item Network Feature 2
\end{itemize}

Similarly we have features for two users in each data item in the testing file but the testing file has no class label. There are 5500 training samples and 5953 testing samples in our data set. Given a test sample, our job is to predict which individual in this test sample is more influential.

\subsection{Kaggle Competition}
The Kaggle competition is hosted at : \cite{kaggle2}. The evaluation for this competition is based on area under the ROC curve. \cite{roc}.

\subsection{Data Preprocessing
}\label{sec:formatting-text}
Since the data is a numerical data, we use some pre-processing techniques on it. The dataset consists of 22 attributes which is essentially 11 attributes for each user in contention. Since we have to compare who is more influential in the network, we subtract related attributes for each user, to reduce the dimensionality to 11. The following is the transformation applied : 
\begin{align*}
a\textsubscript{j} = x\textsubscript{j} - x\textsubscript{j+11}, j = 1,2,3 .... , 11. 
\end{align*}
Since the attributes are of a different scale, we also apply a logarithmic transformation on the data. The following is the transformation applied :
\begin{lstlisting}[language=Python, caption = Log Transformation ]
def transform_features(x):
    return np.log(1 + x)
\end{lstlisting}
All of these transformations are applied to all the models used. In addition to these, we also apply Z-Score normalization on the dataset for using Gausian Na{\"i}ve Bayes model.
\section{SYSTEM MODELS
}\label{sec:fig-tables}
\subsection{Baseline}\label{sec:cap-num}
For baseline, we tried a dumb baseline model, where we classified an influencer based on the number of followers, i.e. if X has more followers than Y, then X is more influential. Using this dumb baseline, we get an accuracy of about \textbf{70.2\%}. This result shows
that the number of followers is a strong indicator
of the influencers. However, 70.2\% is not a very satisfying result and hence we use it only as a benchmark. We know further experiment with more models and a bit more pre-processing. This also suggested that the data can be linearly separable if we choose the right set of features.

\subsection{Logistic Regression}\label{sec:colour-illustrations}
For Logistic Regression, we implemented our own model using two different loss functions : \textit{Logistic Loss} \& \textit{Exponential Loss}. We also used \textit{scikit-learn}'s Logistic Loss for comparison to our own implementation of Logistic Regression. We used Stochastic Gradient Descent for implementing the LR algorithm.

\subsection{SVM}\label{sec:colour-illustrations}
We applied the technique of SVM's with a linear kernel as well as a radial basis kernel function for SVM. For SVM we use scikit learn packages implementation. \cite{svm}

\subsection{Gaussian Na{\"i}ve Bayes}\label{sec:colour-illustrations}
Logistic regression and SVM are discriminative learning algorithms. Gaussian Na{\"i}ve Bayes, is a generative model. The distribution of the original data is not Gaussian, so we tried Z-Score normalization in order to make it as a Gaussian distribution. In Z-Score, we do the following for every value : 
\begin{align*}
z = \frac{x - \mu}{\sigma}
\end{align*}
This converts the data into 0 mean and deviation 1. We then used Gaussian Na{\"i}ve Bayes from \textit{sklearn} package. \cite{gnb}

\subsection{Neural Network}\label{sec:colour-illustrations}
We wanted to explore and see how the date set behaves in a non-linear environment. The idea was to compare the traditional techniques alongside some state of the art machine learning models which have gained a lot of importance today. Hence we implemented a basic Neural Network model in Python to see how it behaves in this classification task. Our model was customizable which means we could add or remove any number of hidden layers with any number of units in each of them. To our surprise the model worked well but didn't outperform the traditional model. The intuition behind this is that the data set and the features we have are linearly separable. 

\subsection{Boosting}
We also used scikit-learn's boosting method : specifically, XgBoost \cite{xgboost}. Boosting is an ensemble classifier which combines several weak classifiers to form a hypothesis. Boosting also has advantages over other classifiers in the fact that it is more robust to overfitting on the training data. 

\section{Tuning the Models}
\subsection{Feature Selection}
We did a correlation plot of all the 11 features with the class label. 
This is represented in Figure \ref{fs_fig}. From the figure we see that there are some features which will not be useful. We were thus motivated to further prune features using a feature selction algorithm.

\begin{figure}
\centering
  \includegraphics[width=200px, height = 200px]{scatter_plt}
  \caption{Scatter plot for co-relation among all the features }
  \label{fs_fig}
\end{figure}
We used forward selection algorithm to zero in on the best features in order to improve the test accuracy. We used Logistic Regression model in order to select the best accuracies for feature selection. The best features are as follows :
\begin{itemize}
\item Follower Count
\item Listed\_Count
\item Retweets Received
\item Network Feature 1
\item Mentions\_Received
\item Network\_Feature2
\end{itemize}

We note that \textit{network\_feature 2} was not showing up as important in the correlation plot, but it's addition to the best features set led to an improvement in accuracy.

\subsection{Cross Validation}
We use held out cross validation, where we partition 80\% of the data as the training set and 20\% of the data as the test set. 

\section{Results \& Discussions}
\subsection{Evaluation Criteria}
The metric that we use to quantify our results was \textit{Area Under the ROC Curve}. ROC is a standard evaluation metric for binary classification problems. We used probabalistic outcomes from the models in order to plot the ROC Curves. \\
For comparing two models, or results from the same model, we compare their AUC values. A ROC Curve with a larger area signifies a better classification model on the given data.\\
To improve our evaluations, we applied k-fold cross validation technique. We try this with a k value of 20. In k-fold cross validation, the model is split into k subsets and is run for k iterations, where k-1 subsets are used to train. The AUC results are averaged across all the iterations.

\subsection{Logistic Regression (Our Implementation)}
For our implementation of Logistic Regression, we tried different loss functions - \textit{Logistic Loss}, \textit{Exponential Loss}. The hyperparameters tuned were : \textit{$\lambda$} (L2 Regularization) \& \textit{$\eta$} (Learning Rate). The results are summarized in Table \ref{tab_lr}. The results in this table are calculated at $\lambda = 0.1 \& \eta = 0.001$.

\begin{table}[!htb]
 \centering
 \caption{AUC for Logistic Regression}
 \label{tab_lr}
\begin{tabular}{ c c c c } 
	    \noalign{\smallskip}\hline\noalign{\smallskip}
		Data &  Loss Function & AUC \\
    	   \noalign{\smallskip}\hline\noalign{\smallskip}
		Train &  Logistic Loss & 0.850868\\
		Dev set & Logistic Loss & 0.8838471\\
		\noalign{\smallskip}\hline\noalign{\smallskip}
		Train &  Exponential Loss & 0.8572271\\
		Dev set & Exponential Loss & 0.88924958\\
		\noalign{\smallskip}\hline\noalign{\smallskip}	
  \end{tabular} 
\end{table}

\subsection{Logistic Regression (From scikit-learn)}
We also tried using Logistic Regression from \textit{scikit-learn} package. We tried tuning the \textit{C} parameter, which is inverse of 	regularization. The best value of C was found to be 100. The following table lists some results. We also evaluate the results with and without feature selection. 

\begin{table}[!htb]
 \centering
 \caption{AUC for Logistic Regression, C = 100}
 \label{tab_lr}
\begin{tabular}{ c c c c } 
	    \noalign{\smallskip}\hline\noalign{\smallskip}
		Data &  Feature Selection & AUC \\
    	   \noalign{\smallskip}\hline\noalign{\smallskip}
		Train &  Yes & 0.8574375\\
		Dev set & No & 0.89348\\
		\noalign{\smallskip}\hline\noalign{\smallskip}
		Train &  Exponential Loss & 0.849165911\\
		Dev set & Exponential Loss & 0.88155468\\
		\noalign{\smallskip}\hline\noalign{\smallskip}	
  \end{tabular} 
\end{table}

In figure \ref{lr_fig} we represent the AUC for Logistic Regression, where the area under the ROC curve is 0.89348.

\begin{figure}
\centering
  \includegraphics[width=200px, height = 200px]{lr_}
  \caption{AUC for Logistic Regression}
  \label{lr_fig}
\end{figure}

So we see, that we get nearly comparable results with both the Logistic Regression implementations, indicating that the data is linearly separable. We thus move onto more linear models.

\subsection{Support Vector Machine (RBF)}
We tried different regularization parameter. The only hyperparameter tuned was : \textit{$C$} (Slack Penalty). The results are summarized in Table \ref{tab_svm2}. The results in this table are calculated at $C = 0.3$.

\begin{table}[!htb]
 \centering
 \caption{AUC for SVM (rbf)}
 \label{tab_svm2}
\begin{tabular}{ c c c } 
	    \noalign{\smallskip}\hline\noalign{\smallskip}
		Data &   AUC \\
    	   \noalign{\smallskip}\hline\noalign{\smallskip}
		Train & 0.9288767\\
		Dev set & 0.8558008\\
				\noalign{\smallskip}\hline\noalign{\smallskip}	
  \end{tabular} 
\end{table}

\subsection{Support Vector Machine (Linear)}
We tried different regularization parameter. The only hyperparameter tuned was : \textit{$C$} (Slack Penalty). The results are summarized in Table \ref{tab_svm}.  The results in this table are calculated at $C = 0.3$.

\begin{table}[!htb]
 \centering
 \caption{AUC for SVM (linear)}
 \label{tab_svm}
\begin{tabular}{ c c c } 
	    \noalign{\smallskip}\hline\noalign{\smallskip}
		Data &   AUC \\
    	   \noalign{\smallskip}\hline\noalign{\smallskip}
		Train & 0.8596409\\
		Dev set & 0.8929928\\
			    \noalign{\smallskip}\hline\noalign{\smallskip}
  \end{tabular} 
\end{table}

So we see, that we get nearly different results with different SVM kernel implementations. This is because the data is linearly separable and hence the linear kernel performs so well.

\subsection{Gaussian Na{\"i}ve Bayes}
With Gaussian Na{\"i}ve Bayes we normalize the data using Z-score normalization, as mentioned in the Pre-Processing. The AUC is presented in Table \ref{nb_tab}.

\begin{table}[!htb]
 \centering
 \caption{AUC for Gaussian Na{\"i}ve Bayes}
 \label{nb_tab}
\begin{tabular}{ c c c } 
	    \noalign{\smallskip}\hline\noalign{\smallskip}
		Data & AUC \\
    	   \noalign{\smallskip}\hline\noalign{\smallskip}
		Train &  0.85311513\\
		Dev Set & 0.88468074\\
		\noalign{\smallskip}\hline\noalign{\smallskip}
  \end{tabular} 
\end{table}

\subsection{Neural Networks}
After trying differ linear models, we did some experiments on non-linear model. We trained and tested the data set on Neural Network. Instead of using a python package, we implemented the code for NN. We tuned the \textit{hidden layer} and \textit{learning rate} parameter,  and tried different loss functions - \textit{Sigmoid Loss}, \textit{tanh Loss}. The data for results of NN is provided in Table \ref{tab_nn}.

\begin{table}[!htb]
 \centering
 \caption{AUC for Neural Networks}
 \label{tab_nn}
\begin{tabular}{ c c c } 
	    \noalign{\smallskip}\hline\noalign{\smallskip}
		Data &  AUC \\
    	   \noalign{\smallskip}\hline\noalign{\smallskip}
		Train &  0.742583466799\\
		Dev set &  0.756661659023\\
				\noalign{\smallskip}\hline\noalign{\smallskip}
  \end{tabular} 
\end{table}

Neural Network did not perform well as expected. This is because of the kind of data set we have at hand. The data set is linearly separable hence the traditional methods outperformed the more complex non-linear model. This shows the significance of data set analysis before model selection because the most promising models may behave differently depending on the features of the data set.  

\subsection{XGBoost Classifier}
In this model we used XGBoost classifier to train our model. We tried tuning various parameters \textit{subsample}, \textit{$\eta$}, \textit{colsample\_bytree}, \textit{max\_depth} and \textit{min\_child\_weight}. The best parameters were found to be \textit{$\eta$} : 0.001, \textit{subsample}: 0.3, \textit{colsample\_bytree}: 0.5, \textit{max\_depth}: 3, \textit{min\_child\_weight}: 9. The following table lists some results.  The number of boosting rounds used was 6000.
 
\begin{table}[!htb]
\centering
\caption{AUC for XGBoost}
\label{tab_xgb}
\begin{tabular}{ c c c }
                    \noalign{\smallskip}\hline\noalign{\smallskip}
                                Data  & AUC \\
                   \noalign{\smallskip}\hline\noalign{\smallskip}
                                Train & 0.86786\\
                                Dev set  & 0.88758\\  
                                		\noalign{\smallskip}\hline\noalign{\smallskip}	                   
  \end{tabular}
\end{table}
 
In Table \ref{tab_xgb} we represent the AUC for XGBoost, where the area under the ROC curve is 0.88758.
 
\begin{figure}
\centering
  \includegraphics[width=200px, height = 200px]{xgboost_dev}
  \caption{AUC for XGBoost}
  \label{xgboost_fig}
\end{figure}

\section{Conclusions}
Our experiments have shown that the models which rely on linear decision boundaries provide the best results on the given dataset. Among the transforms that we used, logarithimic transform proved to be the most effective because it removed the disparity between the various attributes. From the above experiments we can conclude that the AUC for all our models on the dev set varies between 0.87 - 0.89.
The following table provides a summary of AUC scores on Test Dataset for our submissions made on Kaggle website. We present the results of the best values of the models described above that we submitted. All the results presented here were the ones in which we used Feature selection, as well as did Z-Score \& Log normalization of the data.
\begin{table}[!htb]
\centering
\caption{AUC scores for Test Dataset (As per Kaggle Evaluation)}
\label{tab_lr}
\begin{tabular}{ c c c }
 \noalign{\smallskip}\hline\noalign{\smallskip}
   Model  & AUC \\
 \noalign{\smallskip}\hline\noalign{\smallskip}
 Logistic Regression & 0.86065\\
 XgBoost & 0.86168\\
 Gaussian Na{\"i}ve Bayes & 0.84009\\
 Neural Nets & 0.85590\\
 SVM & 0.83786 \\
 		\noalign{\smallskip}\hline\noalign{\smallskip}	
 \end{tabular}
\end{table}

From the table we see that XgBoost performs best since it is an emsemble of several weak classifiers. Followed by XgBoost is Logistic regression. This shows that the data was indeed linearly separable. We also learned about doing an analysis of the dataset, as through our analysis we figured out how the dataset was linearly separable and hence we were able to apply the traditional models instead of the complex models.
Future works on this problem could involve application of PCA to further select combinations of best attributes in order to drive better results.

% (used to reserve space for the reference number labels box)
\begin{thebibliography}{1}
\bibitem{kaggle}
A website for data science competitions. https://www.kaggle.com/
\bibitem{kaggle2}
Influencers in Social Networks : https://www.kaggle.com/c/predict-who-is-more-influential-in-a-social-network
\bibitem{roc}
https://en.wikipedia.org/wiki/Receiver\_operating\_characteristic
\bibitem{svm}
Sci-kit learn Support Vector Machines : http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html
\bibitem{gnb}
Sci-kit learn Gaussian Na{\"i}ve Bayes : http://scikit-learn.org/stable/modules/generated/sklearn.naive\_bayes.GaussianNB.html

\bibitem{xgboost}
XGBoost Library : https://pypi.python.org/pypi/xgboost/

\bibitem{ourrepo}
Our repo is hosted at : https://github.com/piyushghai/Social-Influencers.
\end{thebibliography}

% that's all folks
\end{document}
